### 简化的线程模型 (课程中用于演示)
- heap 表示共享内存
- 两个线程操作 API（[[docs/课程/操作系统/代码/thread-lib/thread.h|thread.h]]）
	- `create(fn)`：创建一个入口是 ` fn ` 的入口函数并立即执行
	- `join()` 等待所有运行线程的返回
### 并发编程中要"放弃"的习惯假设
- **状态迁移原子性**：
	- 共享内存推翻了"原子性"假设
	- 比如 `i++` 就不再具有原子性

- 程序**顺序执行**假设：
```python
def T_sum():
    for _ in range(3):
        t = heap.sum
        sys_sched()
        t = t + 1
        heap.sum = t
        sys_sched()
    sys_write(f'sum = {heap.sum}\n')

def main():
    heap.sum = 0
    sys_spawn(T_sum)
    sys_spawn(T_sum)
    sys_spawn(T_sum)

```
- sum 的最小输出结果为 2（无论多少个线程都是 2）
	- 要想为 2，则说明最后一步执行的是 $1\to2$
	- 也就是一个线程执行完成，一个还剩一次，一个第一次执行（拿的 sum=0）
	- 第一次执行的执行的执行之后 sum 为 1，还剩一次的拿到 1
	- 第一次执行的快速执行完成，还剩一次的执行一次得到 2

- **编译器的优化**可能带来不可预测的结果
	- `while (!flag);` 在优化之后并不会进行反复读取，而是会直接改为死循环，需要添加 `volatile` 阻止优化

- **全局指令执行顺序**的假设
	- 处理器也是**编译器**，会对执行**优化**，只是使得指令 **"看起来"** 顺序完成（可能是针对自己的视角）
	- 比如可以同时执行两条不相关的指令
	- 实际的共享内存模型：不同处理器可能看到**不同的共享内存**
	-  ![image.png|400](https://thdlrt.oss-cn-beijing.aliyuncs.com/20240322120710.png)
```python
def T1():
    heap.x = 1
    sys_sched()
    y_ = heap.y
    sys_sched()
    sys_write(f'{y_}')

def T2():
    heap.y = 1
    sys_sched()
    x_ = heap.x
    sys_sched()
    sys_write(f'{x_}')

def main():
    heap.x, heap.y = 0, 0
    sys_spawn(T1)
    sys_spawn(T2)
```

## 并发控制
### 互斥
- 互斥（互相排斥）：阻止并发
#### Peterson 算法 (用于两个线程)
- 每个人有一个变量（旗子）表示自己是否要使用临界区资源
- 如果要使用临界区资源：
	- 举起**自己的旗子**（先）
	- 把写有**对方名字**的字条贴在临界区上（后）
- 进入观察者模式：
	- 如果**对方没有举起**旗子或者**字条上是自己的名字**就可以使用临界区资源（手快的先进入）
- 释放：放下旗子
```python
def T1():
    while True:
        heap.x = '🏴'
        sys_sched()
        heap.turn = '❷'
        sys_sched()
        while True:
            t = heap.turn
            sys_sched()
            y = heap.y != ''
            sys_sched()
            if not y or t == '❶':
                break
        sys_sched()
        heap.cs += '❶'
        sys_sched()
        heap.cs = heap.cs.replace('❶', '')
        sys_sched()
        heap.x = ''
        sys_sched()
 
def T2():
    while True:
        heap.y = '🏁'
        sys_sched()
        heap.turn = '❶'
        sys_sched()
        while True:
            t = heap.turn
            sys_sched()
            x = heap.x
            sys_sched()
            if not x or t == '❷':
                break
            sys_sched()
        sys_sched()
        heap.cs += '❷'
        sys_sched()
        heap.cs = heap.cs.replace('❷', '')
        sys_sched()
        heap.y = ''
        sys_sched()

def main():
    heap.x = ''
    heap.y = ''
    heap.turn = ''
    heap.cs = ''
    sys_spawn(T1)
    sys_spawn(T2)

```
#### 多处理器上的互斥
- **原子指令**：一小段时间的 “Stop the World” 执行
	- 如**不可打断的** `load+计算+save`
	- 汇编中添加 `lock` 前缀
- 这样就可以更简单的进行互斥
```python
int status = ✅;

void lock() {
retry:
    if (status != ✅) {
        goto retry;
    }
    status = ❌;
}

void unlock() {
    status = ✅;
}
```

- **自旋锁**：
	- 使用原子交换来实现自旋锁，不同线程与自旋锁进行交换，但是只有一个可以交换得到权利使用资源
	- ![image.png|500](https://thdlrt.oss-cn-beijing.aliyuncs.com/20240322163639.png)
#### 操作系统内核中的互斥
- 中断带来了一系列麻烦
	- 比如在获得锁（lock ()）的状态下发生中断，并且中断程序执行中也要获取这个锁，那么就出现了死锁
- 正确性标准
	- 正确实现互斥：**关中断**（lock 之前关中断，unlock 之后开中断，也不一定要开，比如执行的是一个中断处理程序时就不应该开中断）**+自旋保证实现互斥**
	- 上锁、解锁前后中断状态不变：
		- 加锁是想把一段操作作为原子操作，除此之外不该改动其他属性（如关中断状态）
		- 不得在关中断时**随意打开中断** (例如处理中断时)
		- 不得随意**关闭中断** (否则可能导致中断丢失)

##### 操作系统内核中的 **(半)无锁** 互斥
- 当线程超过一定数目时**自旋锁**会成为**性能瓶颈**（甚至 CPU 越多性能反而更差）
- 利用操作系统内核对象“read-mostly”的性质（经常读取但是很少进行修改）
- Read-Copy-Update（RCU）主要用于提高在读操作频繁而写操作较少的情况下的性能和可伸缩性。
	- RCU 的基本思想是当数据结构需要更新时，不直接在原有数据结构上进行修改，而是**先复制一份数据**，在这份副本上做修改。修改完成后，再将读取操作从旧的数据结构**切换**到这份已修改的副本上。此过程中，旧的数据结构仍然可以被读取操作访问，直到确定没有任何读取操作在使用旧数据后，才将其回收。
	- 划分为三个阶段：复制-更新-发布
	- 牺牲了一定的数据一致性
#### 应用程序中的互斥
- **互斥锁**
- 自旋锁的效率问题：除了进入临界区的线程，其他处理器上的线程都在空转，争抢锁的处理器越多效率越低。如果临界区较长不如把处理器让给其他线程（此外如果持有自旋锁的线程被切换，那甚至还会有 100%的资源浪费）
- 也就是说预期白白等待不如把 CPU 让给其他线程来使用
	- 使用 syscall 进入内核，操作系统尝试获取锁，如果**失败**那么就**先切换线程**，标记为等待
	- 当锁被释放时再唤醒等待锁的线程
### 同步
- 互斥只解决了原子性的问题，保证同时只能有一个相关操作正在进行，但是并不能用于**协调相对关系**，比如想先完成一件事再做另一件事 
- 同步用于对多个线程的**执行顺序**进行控制：使得两个或两个以上随时间变化的量**在变化过程中保持一定的相对关系**
- 乐团演奏的简单例子
```c
void T_player() {
    while (!end) {
        wait_next_beat();
        play_next_note();
    }
}
void wait_next_beat(int expect) {
    // This is a spin-wait loop.
retry:
    mutex_lock(&lk);
    // This read is protected by a mutex.
    int got = n;
    mutex_unlock(&lk);

    if (got != expect) goto retry;
}
```
- 在拍子内演奏者各自活动，但是在节拍到来时同意行动（完成一个节拍的演奏）
#### 生产者-消费者问题与条件变量
- 99% 的实际并发问题都可以用生产者-消费者解决
- 存在一个大小有限的缓冲区
	- Producer (生产数据)：如果缓冲区有空位，**放入**；否则等待
	- Consumer (消费数据)：如果缓冲区有数据，**取走**；否则等待
- 通过括号匹配来检查模型的正确性
	- ![image.png|500](https://thdlrt.oss-cn-beijing.aliyuncs.com/20240331231818.png)
- 使用互斥锁的基础实现
	- 问题：反复检查占用CPU
```c
#include <thread.h>
#include <thread-sync.h>

mutex_t lk = MUTEX_INIT();

int n, depth = 0;

void T_produce() {
    while (1) {
retry:
        mutex_lock(&lk);
        if (!(depth < n)) {
            mutex_unlock(&lk);
            goto retry;
        }
        assert(depth < n);
        printf("(");
        depth++;

        mutex_unlock(&lk);
    }
}

void T_consume() {
    while (1) {
retry:
        mutex_lock(&lk);
        if (!(depth > 0)) {
            mutex_unlock(&lk);
            goto retry;
        }
        assert(depth > 0);
        printf(")");
        depth--;

        mutex_unlock(&lk);
    }
}
```
- 使用**条件变量**的方式
	- 替代自旋锁，提升效率
	- 条件不满足时等待，条件满足时唤醒
```c
int n, depth = 0;
mutex_t lk = MUTEX_INIT();
cond_t cv = COND_INIT();
 
#define CAN_PRODUCE (depth < n)
#define CAN_CONSUME (depth > 0)

void T_produce() {
    while (1) {
        mutex_lock(&lk);

        while (!CAN_PRODUCE) {
            cond_wait(&cv, &lk);
            //条件不满足时，调用条件变量等待（直到条件变量发生变化）（系统会进行休眠），并且此方法还负责先释放锁，等到继续时再重新加锁
            //之后使用while还会额外进行一次检查，因为这里生产者和消费者共用一个锁，这条件变量改变不代表条件一定满足
        }

        // We still hold the mutex--and we check again.
        assert(CAN_PRODUCE);

        printf("(");
        depth++;
		//条件变量发生改变时进行唤醒广播
        cond_broadcast(&cv);
        mutex_unlock(&lk);
    }
}

void T_consume() {
    while (1) {
        mutex_lock(&lk);

        while (!CAN_CONSUME) {
            cond_wait(&cv, &lk);
        }

        printf(")");
        depth--;

        cond_broadcast(&cv);
        mutex_unlock(&lk);
    }
}
```
#### 同步机制的应用
- 将任务分解为有向无环图，调度者（生产者）进行任务拓扑分配，将任务分配给消费者来执行
	- 只要调度器 (生产者) 分配任务效率够高，算法就能并行
	- (将任务丢到线程池)
```c
void T_worker() {
    while (1) {
        consume().run();
    }
}
void T_scheduler() {
    while (!jobs.empty()) {
        for (auto j : jobs.find_ready()) {
            produce(j);
        }
    }
}
```
- 使用条件变量的实现
	- 为每一个节点设置一个条件变量
	- 一个节点 $v$ 能执行的条件是所有 $u\to v$ 都已经完成
	- $u$ 完成之后，signal 每一个 $u\to v$
- 一个问题能不能很好的并行化，就是取决于其计算图（有向无环图）的结构，是否能很好的划分，当紧密依赖（如类似链表形式）就很难进行并行化

- 例子：多个线程分别输出<>\_中的某一种，要求只能输出这几种图案<><_ 和><>_
	- 使用状态机表示，一个线程能够打印的条件就是当前状态可以使用当前字符进行状态转移
	- [[docs/课程/操作系统/代码/fish/fish.c|fish]]
#### 使用信号量实现同步
- 首先考虑使用互斥锁实现同步，还是音乐演奏，指挥者负责对锁进行解锁，演奏者尝试获得锁，得到锁之后进行演奏，完成后上锁（注意要求锁的实现必须支持跨线程操作）
- 使用互斥锁实现计算图：
	- 为每一条边分配互斥锁，初始化时全部锁定
	- 对于一个节点，需要获得所有入边的锁才能继续
	- 计算完成后，释放出边对应的锁
```c
void T_worker(int id) {
    for (int i = 0; i < LENGTH(edges); i++) {
        struct Edge *e = &edges[i];
        if (e->to == id) {
            mutex_lock(&e->mutex);
        }
    }

    printf("Start %d\n", id);
    sleep(1);
    printf("End %d\n", id);
    sleep(1);

    for (int i = 0; i < LENGTH(edges); i++) {
        struct Edge *e = &edges[i];
        if (e->from == id) {
            // Well... This is undefined behavior
            // for POSIX threads. This is just a
            // hack for demonstration.
            mutex_unlock(&e->mutex);
        }
    }
}

int main() {
    for (int i = 0; i < LENGTH(edges); i++) {
        struct Edge *e = &edges[i];
        mutex_lock(&e->mutex);
    }

    for (int i = 0; i < N; i++) {
        create(T_worker);
    }
}
```

- 只使用互斥锁的灵活性较差，比如游泳馆需要先拿手环才能进入更衣室，但是不是一次只能进一人，而是希望控制同时有 n 人在更衣室，这就要使用"能**计数**"的互斥锁，就是**信号量**
- 信号量分为 P (acquire) V（release）两种操作
	- 当信号量容量限制为 1 时就是互斥锁
```c
void P(sem_t *sem) {
    // P - prolaag
    //     try + decrease/down/wait/acquire
    atomic {
        wait_until(sem->count > 0) {
            sem->count--;
        }
    }
}

void V(sem_t *sem) {
    // V - verhoog
    //     increase/up/post/signal/release
    atomic {
        sem->count++;
    }
}
```
##### 信号量的应用
- 简单信号量：使用 PV 代替加锁解锁操作，代替互斥锁实现同步；
- 管理计数型资源；
- join 的实现
```c
int count;
sem_t done;

void worker_init(int T) {
    count = T;
    SEM_INIT(&done, 0);
}

void worker_done(int id) {
    V(&done);//完成一个任务，信号量加一
}

void worker_join() {
    for (int i = 0; i < count; i++) {
        P(&done);//需要三个信号量，即任务全部完成才能继续
    }
}
//使用方式
int main() {
    worker_init(4);

    for (int i = 0; i < 4; i++) {
        create(T_worker);
    }

    worker_join();
    printf("Workers joined.\n");
}

```
- 使用信号量解决生产者消费者问题
	- 使用两个信号量，empty 维护了缓冲区的容量（即生产者最多放入多少个任务），消费者从 fill 取出任务，执行完成后放回 empty
```c
void produce() {
    P(&empty);
    printf("(");
    V(&fill);
}

void consume() {
    P(&fill);
    printf(")");
    V(&empty);
}
```
 
#### 同步方式间的关系与对比
- 信号量
	- 互斥锁的自然推广
	- 干净、优雅：没有条件变量的 “自旋”
- 条件变量
	- **万能**：适用于任何同步条件，能处理更加复杂的问题
	- 不太好用：代码总感觉不太干净

-  通过信号量直接实现哲学家吃饭会存在死锁
```c
void Tphilosopher(int id) {
    int lhs = (id + N - 1) % N;
    int rhs = id % N;

    while (1) {
        // Come to table
        // P(&table);

        P(&avail[lhs]);
        printf("+ %d by T%d\n", lhs, id);
        P(&avail[rhs]);
        printf("+ %d by T%d\n", rhs, id);

        // Eat.
        // Philosophers are allowed to eat in parallel.

        printf("- %d by T%d\n", lhs, id);
        printf("- %d by T%d\n", rhs, id);
        V(&avail[lhs]);
        V(&avail[rhs]);

        // Leave table
        // V(&table);
    }
}
```
- 使用条件变量改进，只有当两个叉子都可用时才同时拿起 `avail[lhs] && avail[rhs]`
- 从桌子上赶走一个人，提那家一个信号量控制上桌吃饭的人数
- 一个人反着拿，如都先拿编号小的叉子

- 用条件变量实现信号量
```c
void P(sem_t *sem) {
    hold(&sem->mutex) {
        while (!COND)
            cond_wait(&sem->cv, &sem->mutex);
        sem->count--;
    }
}

void V(sem_t *sem) {
    hold(&sem->mutex) {
        sem->count++;
        cond_broadcast(&sem->cv);
    }
}
```
- 用信号量实现条件变量
```c
void wait(struct condvar *cv, mutex_t *mutex) {
    mutex_lock(&cv->lock);
    //更新正在等待的数目
    cv->nwait++;
    mutex_unlock(&cv->lock);
	//释放原先线程的锁进行休眠
    mutex_unlock(mutex);
    //!！此处放弃了mutex的锁，如果此时发生broadcast可能出错，比如broadcast的信号量被其他消费者使用了，而没有用到此线程上;并且很难解决，因为必须在P之前先释放锁
    // 信号量无法实现这种机制，其实还是需要条件变量来实现release-wait的原子操作
    //等待信号量
    P(&cv->sleep);
	//重新加锁
    mutex_lock(mutex);
}

void broadcast(struct condvar *cv) {
    mutex_lock(&cv->lock);
	//加入对应等待者数目的信号量
    for (int i = 0; i < cv->nwait; i++) {
        V(&cv->sleep);
    }
    cv->nwait = 0;

    mutex_unlock(&cv->lock);
}
```
- 
## 并发 bug
- bug 的触发需要：编译器+编译选型+特别的机器+运气
- 初学者应该只用"绝对正确"的实现
	-  `atomic_xchg`
	- `pthread_mutex_lock`
### 调试理论
- 需求-设计-代码（Fault/Bug 目标）-执行（Error）-失败（Failure 可以观测的结果错）
	- 调试困难的原因：error 和 failure 距离太远。应该平凡进行检查（如 assert）缩短距离
> 如果我们能判定任意程序状态的正确性，那么给定一个 failure，我们可以通过二分查找定位到**第一个** error 的状态，此时的代码就是 fault (bug)。

- 调试 = 观察状态机执行 (trace) 的某个侧面
	- **缩小**错误状态可能产生的**位置**（对程序进行划分）
	- 提出假设，作出验证

- printf：灵活可控、能快速定位问题**大概位置**、适用于大型软件；**无法精确定位**、大量的 logs 管理起来比较麻烦
- gdb：**精确**、指令级定位、任意查看程序内部状态；**耗费大量时间**

- ![image.png|475](https://thdlrt.oss-cn-beijing.aliyuncs.com/20240323005003.png)

- `-fsanitize=address ` 使用动态程序分析，如判断是否有数组越界


