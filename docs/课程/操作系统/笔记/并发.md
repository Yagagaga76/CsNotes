### 简化的线程模型 (课程中用于演示)
- heap 表示共享内存
- 两个线程操作 API（[[docs/课程/操作系统/代码/thread-lib/thread.h|thread.h]]）
	- `create(fn)`：创建一个入口是 ` fn ` 的入口函数并立即执行
	- `join()` 等待所有运行线程的返回
### 并发编程中要"放弃"的习惯假设
- **状态迁移原子性**：
	- 共享内存推翻了"原子性"假设
	- 比如 `i++` 就不再具有原子性

- 程序**顺序执行**假设：
```python
def T_sum():
    for _ in range(3):
        t = heap.sum
        sys_sched()
        t = t + 1
        heap.sum = t
        sys_sched()
    sys_write(f'sum = {heap.sum}\n')

def main():
    heap.sum = 0
    sys_spawn(T_sum)
    sys_spawn(T_sum)
    sys_spawn(T_sum)

```
- sum 的最小输出结果为 2（无论多少个线程都是 2）
	- 要想为 2，则说明最后一步执行的是 $1\to2$
	- 也就是一个线程执行完成，一个还剩一次，一个第一次执行（拿的 sum=0）
	- 第一次执行的执行的执行之后 sum 为 1，还剩一次的拿到 1
	- 第一次执行的快速执行完成，还剩一次的执行一次得到 2

- **编译器的优化**可能带来不可预测的结果
	- `while (!flag);` 在优化之后并不会进行反复读取，而是会直接改为死循环，需要添加 `volatile` 组织优化

- **全局指令执行顺序**的假设
	- 处理器也是**编译器**，会对执行**优化**，只是使得指令 **"看起来"** 顺序完成（可能是针对自己的视角）
	- 比如可以同时执行两条不想关的指令
	- 实际的共享内存模型：不同处理器可能看到**不同的共享内存**
	-  ![image.png|400](https://thdlrt.oss-cn-beijing.aliyuncs.com/20240322120710.png)
```python
def T1():
    heap.x = 1
    sys_sched()
    y_ = heap.y
    sys_sched()
    sys_write(f'{y_}')

def T2():
    heap.y = 1
    sys_sched()
    x_ = heap.x
    sys_sched()
    sys_write(f'{x_}')

def main():
    heap.x, heap.y = 0, 0
    sys_spawn(T1)
    sys_spawn(T2)
```
## 并发控制
### 互斥
- 互斥（互相排斥）：阻止并发
#### Peterson 算法 (用于两个线程)
- 每个人有一个变量（旗子）表示自己是否要使用临界区资源
- 如果要使用临界区资源：
	- 举起**自己的旗子**（先）
	- 把写有**对方名字**的字条贴在临界区上（后）
- 进入观察者模式：
	- 如果**对方没有举起**旗子或者**字条上是自己的名字**就可以使用临界区资源（手快的先进入）
- 释放：放下旗子
```python
def T1():
    while True:
        heap.x = '🏴'
        sys_sched()
        heap.turn = '❷'
        sys_sched()
        while True:
            t = heap.turn
            sys_sched()
            y = heap.y != ''
            sys_sched()
            if not y or t == '❶':
                break
        sys_sched()
        heap.cs += '❶'
        sys_sched()
        heap.cs = heap.cs.replace('❶', '')
        sys_sched()
        heap.x = ''
        sys_sched()
 
def T2():
    while True:
        heap.y = '🏁'
        sys_sched()
        heap.turn = '❶'
        sys_sched()
        while True:
            t = heap.turn
            sys_sched()
            x = heap.x
            sys_sched()
            if not x or t == '❷':
                break
            sys_sched()
        sys_sched()
        heap.cs += '❷'
        sys_sched()
        heap.cs = heap.cs.replace('❷', '')
        sys_sched()
        heap.y = ''
        sys_sched()

def main():
    heap.x = ''
    heap.y = ''
    heap.turn = ''
    heap.cs = ''
    sys_spawn(T1)
    sys_spawn(T2)

```
#### 多处理器上的互斥
- **原子指令**：一小段时间的 “Stop the World” 执行
	- 如**不可打断的** `load+计算+save`
	- 汇编中添加 `lock` 前缀
- 这样就可以更简单的进行互斥
```python
int status = ✅;

void lock() {
retry:
    if (status != ✅) {
        goto retry;
    }
    status = ❌;
}

void unlock() {
    status = ✅;
}
```

- **自旋锁**：
	- 使用原子交换来实现自旋锁，不同线程与自旋锁进行交换，但是只有一个可以交换得到权利使用资源
	- ![image.png|500](https://thdlrt.oss-cn-beijing.aliyuncs.com/20240322163639.png)
#### 操作系统内核中的互斥
- 中断带来了一系列麻烦
	- 比如在获得锁（lock ()）的状态下发生中断，并且中断程序执行中也要获取这个锁，那么就出现了死锁
- 正确性标准
	- 正确实现互斥：**关中断**（lock 之前关中断，unlock 之后开中断，也不一定要开，比如执行的是一个中断处理程序时就不应该开中断）**+自旋保证实现互斥**
	- 上锁、解锁前后中断状态不变：
		- 加锁是想把一段操作作为原子操作，除此之外不该改动其他属性（如关中断状态）
		- 不得在关中断时**随意打开中断** (例如处理中断时)
		- 不得随意**关闭中断** (否则可能导致中断丢失)

##### 操作系统内核中的 **(半)无锁** 互斥
- 当线程超过一定数目时**自旋锁**会成为**性能瓶颈**（甚至 CPU 越多性能反而更差）
- 利用操作系统内核对象“read-mostly”的性质（经常读取但是很少进行修改）
- Read-Copy-Update（RCU）主要用于提高在读操作频繁而写操作较少的情况下的性能和可伸缩性。
	- RCU 的基本思想是当数据结构需要更新时，不直接在原有数据结构上进行修改，而是**先复制一份数据**，在这份副本上做修改。修改完成后，再将读取操作从旧的数据结构**切换**到这份已修改的副本上。此过程中，旧的数据结构仍然可以被读取操作访问，直到确定没有任何读取操作在使用旧数据后，才将其回收。
	- 划分为三个阶段：复制-更新-发布
	- 牺牲了一定的数据一致性
#### 应用程序中的互斥
- **互斥锁**
- 自旋锁的效率问题：除了进入临界区的线程，其他处理器上的线程都在空转，争抢锁的处理器越多效率越低。如果临界区较长不如把处理器让给其他线程（此外如果持有自旋锁的线程被切换，那甚至还会有 100%的资源浪费）
- 也就是说预期白白等待不如把 CPU 让给其他线程来使用
	- 使用 syscall 进入内核，操作系统尝试获取锁，如果**失败**那么就**先切换线程**，标记为等待
	- 当锁被释放时再唤醒等待锁的线程
### 同步
- 互斥只解决了原子性的问题，保证同时只能有一个相关操作正在进行，但是并不能用于**协调相对关系**，比如想先完成一件事再做另一件事 
- 同步用于对多个线程的**执行顺序**进行控制：使得两个或两个以上随时间变化的量**在变化过程中保持一定的相对关系**
- 乐团演奏的简单例子
```c
void T_player() {
    while (!end) {
        wait_next_beat();
        play_next_note();
    }
}
void wait_next_beat(int expect) {
    // This is a spin-wait loop.
retry:
    mutex_lock(&lk);
    // This read is protected by a mutex.
    int got = n;
    mutex_unlock(&lk);

    if (got != expect) goto retry;
}
```
- 在拍子内演奏者各自活动，但是在节拍到来时同意行动（完成一个节拍的演奏）
#### 生产者-消费者问题与条件变量
- 99% 的实际并发问题都可以用生产者-消费者解决
- 存在一个大小有限的缓冲区
	- Producer (生产数据)：如果缓冲区有空位，**放入**；否则等待
	- Consumer (消费数据)：如果缓冲区有数据，**取走**；否则等待
- 通过括号匹配来检查模型的正确性
	- ![image.png|500](https://thdlrt.oss-cn-beijing.aliyuncs.com/20240331231818.png)
- 使用互斥锁的基础实现
```c
mutex_t lk = MUTEX_INIT();

int n, depth = 0;

void T_produce() {
    while (1) {
retry:
        mutex_lock(&lk);
        int ready = (depth < n);
        mutex_unlock(&lk);
        if (!ready) goto retry;

        // assert(depth < n);

        mutex_lock(&lk);
        printf("(");
        depth++;
        mutex_unlock(&lk);
    }
}

void T_consume() {
    while (1) {
retry:
        mutex_lock(&lk);
        int ready = (depth > 0);
        mutex_unlock(&lk);
        if (!ready) goto retry;

        // assert(depth > 0);

        mutex_lock(&lk);
        printf(")");
        depth--;
        mutex_unlock(&lk);
    }
}
```
- 
#### 同步机制的应用
- 
### 并发 bug
- bug 的触发需要：编译器+编译选型+特别的机器+运气
- 初学者应该只用"绝对正确"的实现
	-  `atomic_xchg`
	- `pthread_mutex_lock`
#### 调试理论
- 需求-设计-代码（Fault/Bug 目标）-执行（Error）-失败（Failure 可以观测的结果错）
	- 调试困难的原因：error 和 failure 距离太远。应该平凡进行检查（如 assert）缩短距离
> 如果我们能判定任意程序状态的正确性，那么给定一个 failure，我们可以通过二分查找定位到**第一个** error 的状态，此时的代码就是 fault (bug)。

- 调试 = 观察状态机执行 (trace) 的某个侧面
	- **缩小**错误状态可能产生的**位置**（对程序进行划分）
	- 提出假设，作出验证

- printf：灵活可控、能快速定位问题**大概位置**、适用于大型软件；**无法精确定位**、大量的 logs 管理起来比较麻烦
- gdb：**精确**、指令级定位、任意查看程序内部状态；**耗费大量时间**

- ![image.png|475](https://thdlrt.oss-cn-beijing.aliyuncs.com/20240323005003.png)

- `-fsanitize=address ` 使用动态程序分析，如判断是否有数组越界
