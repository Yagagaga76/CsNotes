## 个人相关
### 自我介绍
Hi, my name is Tian Haodong, and I'm a student at Nanjing University, majoring in Computer Science and Finance. I enjoy learning new things and sharing my notes on my blog. I've kept good grades, ranking 3rd in my class, and I've won the Excellence Scholarship for two years in a row.

I've worked on many projects and joined several competitions. For example, I led a team in the Nanjing University-NetEase Game Competition, where we made an RTS game using C# and Unity. This made me very interested in the game industry and computer graphics.

I'm also good at data structures and algorithms. I won a gold medal[ˈmed(ə)l] in the Nanjing University Programming Contest and scored in the top 1.33% in the CCF-CSP exam. I taught myself computer graphics and completed projects like a rasterizer[ˈræs.tə.raɪz] and a simple ray tracer, which helped me understand graphics better.

I'm very interested in real-time rendering and hope to contribute to improving visuals and performance in future games or AR applications. I look forward to continuing my studies and growing in this field.
### 介绍家乡
I'm from Shenyang, the capital city of Liaoning Province in northeastern China. Shenyang is a city with a long history and lots of culture. It's famous for being the birthplace of the Qing Dynasty. You can visit the Shenyang Imperial[ɪmˈpɪriəl] Palace, which is a really cool historic site.

Shenyang is also a big industrial[ɪnˈdʌstriəl] city, known for its car and airplane factories. But it's not all factories  we have beautiful parks like Beiling Park and the Botanical[bəˈtænɪk(ə)l] Garden where people can relax and enjoy nature.

One of my favorite things about Shenyang is the food. We have amazing local dishes, like Shenyang dumplings and Laobian dumplings. The street food is also great, with lots of tasty snacks to try. One of the most famous street foods is "chicken rack" (鸡架), which is very popular among locals. 

Shenyang is a place where you can see both old traditions and modern life. It's a great city with a lot to offer, and I'm proud to call it my hometown.
### 最喜欢的课程
One of my favorite courses in computer science is Algorithm Design and Analysis. This course has significantly deepened my understanding of fundamental algorithms and their analysis. We started with sorting problems to introduce the divide-and-conquer strategy and heap data structures. As the course progressed, we delved[delvd] into more advanced data structures like disjoint sets, red-black trees, and hash tables. Later, we combined these concepts with graph theory to explain common algorithms such as minimum spanning trees. The course also covered greedy algorithms and dynamic programming, providing a comprehensive overview of essential algorithmic strategies.

In class, this theoretical[ˌθiəˈretɪk(ə)l] foundation helped me grasp the complexities of various algorithms. We also solved problems on online judges, which improved my coding and problem-solving skills.

Outside of class, I have been very active in self-study and competitions. Since my freshman year, I have been solving problems on LeetCode and participating in weekly contests. This has greatly enhanced my algorithm skills. From my junior year, I delved deeper into competitive programming and participated in various contests. Such as scoring in the top 1.33%（*one point three three percent*） in the CCF-CSP Certification exam and winning a gold medal in the Nanjing University Programming Contest. These experiences have solidified[səˈlɪdɪˌfaɪ] my interest and skills in algorithm.
### 优势
As an undergraduate at Nanjing University, I have developed solid coding skills through various projects. For example, I led a team in the Nanjing University-NetEase ThunderFire Game Competition to develop an RTS game using C# and Unity. I also have a good understanding of algorithms and data structures, as shown by my participation in competitions like CCF CSP (355 points, top 1.33%) I  winning a gold medal in the Nanjing University Programming Contest

My academic performance has been strong, with a GPA of 4.58, ranking in the top 7.5% of my class. I excelled in courses like Data Structures and Algorithms (98), Advanced Programming (96), and Computer Systems (95). These experiences have provided me with a good foundation for further studies and research in computer science.
### 为什么想要再南大读研

## 专业问题
### 二叉搜索树
A Binary Search Tree (BST) is a type of binary tree where each node has at most two children. The key rule is that the left child has a smaller value, and the right child has a larger value. This structure makes searching, inserting, and deleting values efficient.

To search, start at the root, compare the value, and move left or right accordingly until you find the value or reach a leaf. Inserting works the same way, and you place the new value where you find a suitable spot. Deletion involves replacing the node with its in-order successor[səkˈsesər] or predecessor[ˈpredəˌsesər] if it has two children.

In a balanced BST, search, insert, and delete operations take O(log n) time. In the worst case, if the tree is unbalanced, these operations take O(n) time.
### 死锁
Deadlock is a situation in computer systems where two or more processes cannot continue because each one is waiting for the other to release a resource. This happens when four conditions occur at the same time:
1. Processes must hold resources that others need.
2. Processes keep their resources while waiting for more.
3. Resources cannot be taken away; 
4. A cycle of processes exists, where each process waits for a resource held by the next process in the cycle.
### 快速排序
Quicksort is a fast sorting algorithm used to arrange numbers or other items in order. It works by selecting a "pivot[ˈpɪvət]" element from the array and then rearranging[ˌriəˈreɪndʒ] the other elements into two groups: those less than the pivot and those greater than the pivot. The pivot is then in its final position. This process is repeated for the two groups, recursively sorting the sub-arrays.
Quicksort is efficient with an average time complexity of O(n log n), but in the worst case, it can be O(n^2). However, with good pivot selection, it usually performs very well.
### 冒泡排序
Bubble Sort is a simple sorting algorithm that arranges items in order by repeatedly stepping through the list, comparing each pair of adjacent[əˈdʒeɪs(ə)nt] items, and swapping them if they are in the wrong order.  You then start again from the beginning and repeat the process until no swaps are needed, meaning the list is sorted. Bubble Sort has a time complexity of O(n^2), which makes it inefficient for large lists, but it is easy to understand and implement.
### 归并排序
Merge Sort is a sorting algorithm that uses a divide and conquer approach to sort items. It works by dividing the list into smaller sublists until each sublist has only one item. Then, it repeatedly merges these sublists to produce new sorted sublists until there is only one sorted list remaining. The main steps are to split the list into halves, sort each half, and then merge the sorted halves together. Merge Sort has a time complexity of O(n log n), making it efficient for large lists.
### 希尔排序
Shell Sort is an advanced version of insertion sort that improves efficiency by comparing and sorting elements that are far apart. It starts by sorting elements with a large gap between them, then progressively[prəʊˈɡresɪvli] reduces the gap and sorts the elements again. This process continues until the gap is 1, at which point it performs a final insertion sort. By starting with larger gaps, Shell Sort moves elements closer to their final position faster, which reduces the total number of movements needed. The time complexity of Shell Sort can vary, but it generally performs much better than O(n^2) for large lists.
### 选择排序
Selection Sort is a simple comparison-based sorting algorithm. It works by repeatedly selecting the smallest element from the unsorted portion of the list and swapping it with the first unsorted element.
Selection Sort works as follows:

1. Start with the first element as the current minimum.
2. Scan the remaining unsorted portion of the list to find the smallest element.
3. Swap the smallest element found with the first unsorted element.
4. Move the boundary between sorted and unsorted portions one element to the right.
5. Repeat steps 1-4 until the entire list is sorted.

The time complexity of Selection Sort is O(n^2)
### 插入排序
Insertion Sort is a simple and intuitive sorting algorithm. It builds the final sorted list one element at a time by repeatedly picking the next element and inserting it into its correct position among the previously sorted elements.
Insertion Sort works as follows:

1. Start with the second element, considering the first element as a sorted sublist.
2. Compare the current element with the elements in the sorted sublist.
3. Shift all elements in the sorted sublist that are greater than the current element one position to the right.
4. Insert the current element into its correct position.
5. Move to the next element and repeat steps 2-4 until the entire list is sorted.

The time complexity of Insertion Sort is O(n^2) in the worst case
### TCP/IP
TCP (Transmission Control Protocol) and IP (Internet Protocol) are two key protocols for network communication. TCP ensures reliable data transmission by dividing data into small packets, ensuring packets arrive in order, and handling packet loss. IP is responsible for addressing and routing these packets so they can travel from the sender to the receiver.

The TCP/IP model is typically described as a five-layer structure:
1. **Physical Layer**: Handles the physical connection between devices.
2. **Data Link Layer**: Manages node-to-node data transfer and error detection.
3. **Network Layer**: Uses IP to address and route packets between devices.
4. **Transport Layer**: Uses TCP to ensure reliable data transfer and correct packet sequencing.
5. **Application Layer**: Supports application services and end-user processes, like HTTP, FTP, etc.
This five-layer model ensures data can be reliably and correctly transmitted between network devices.
### kruskal
Kruskal's algorithm is a method used to find the minimum spanning tree (MST) of a weighted, undirected graph. The MST is a subset of the graph's edges that connects all vertices with the minimum possible total edge weight and no cycles.

Kruskal's algorithm works as follows:
1. Sort all edges in the graph by their weight in ascending order.
2. Initialize an empty set for the MST.
3. Iterate through the sorted edges, adding each edge to the MST if it doesn't form a cycle with the edges already in the MST.
4. Continue this process until the MST contains exactly 𝑛−1 edges

The time complexity of Kruskal's algorithm is 𝑂(𝐸log⁡𝐸), where 𝐸 is the number of edges, primarily due to the sorting step. 
### prim
Prim's algorithm is a method used to find the minimum spanning tree (MST) of a weighted, undirected graph. The MST connects all vertices with the minimum possible total edge weight and no cycles.
Prim's algorithm works as follows:

1. Start with a single vertex and consider it as part of the MST.
2. Find the smallest edge connecting a vertex in the MST to a vertex outside the MST.
3. Add this edge and the vertex to the MST.
4. Repeat until all vertices are included in the MST.

Prim's algorithm typically uses a priority queue to efficiently find the smallest edge. The time complexity of Prim's algorithm is 𝑂(𝐸log⁡𝑉) with a priority queue, where 𝐸 is the number of edges and 𝑉 is the number of vertices.
### Dijkstra
Dijkstra's algorithm is used to find the shortest path from a single source vertex to all other vertices in a weighted, directed graph with non-negative edge weights.
Dijkstra's algorithm works as follows:

1. Initialize the distance to the source vertex as 0 and to all other vertices as infinity.
2. Set the source vertex as the current vertex and mark it as visited.
3. For the current vertex, update the distances to its adjacent vertices. If a shorter path is found, update the distance.
4. Select the unvisited vertex with the smallest distance as the new current vertex.
5. Repeat steps 3 and 4 until all vertices are visited or the smallest distance among the unvisited vertices is infinity.

Dijkstra's algorithm uses a priority queue to efficiently select the vertex with the smallest distance. The time complexity is 𝑂(𝑉log⁡𝑉+𝐸log⁡𝑉), where 𝑉 is the number of vertices and 𝐸 is the number of edges, typically when implemented with a priority queue.
### bellman-ford
The Bellman-Ford algorithm is used to find the shortest paths from a single source vertex to all other vertices in a weighted, directed graph. It can handle graphs with negative edge weights.
Bellman-Ford works as follows:

1. Initialize the distance to the source vertex as 0 and the distance to all other vertices as infinity.
2. For each vertex, repeat the following process (|V| - 1) times, where |V| is the number of vertices:
    - For each edge (u, v) with weight w, if the distance to u plus w is less than the distance to v, update the distance to v.
3. After |V| - 1 iterations, check for negative-weight cycles by iterating through all edges again. If a shorter path is found, it indicates the presence of a negative-weight cycle.

The time complexity of the Bellman-Ford algorithm is O(VE). 
### floyd
The Floyd-Warshall algorithm is used to find the shortest paths between all pairs of vertices in a weighted graph. It can handle graphs with both positive and negative edge weights.
Floyd-Warshall works as follows:

1. Create a distance matrix to store the shortest distance between every pair of vertices, initializing it with the edge weights from the graph. If there is no edge between two vertices, set the distance to infinity, except for the diagonal where the distance is zero.
2. Iterate through each vertex as an intermediate point and update the distance matrix. For each pair of vertices (i, j), check if a path through an intermediate vertex k offers a shorter path. If so, update the distance matrix with this new shorter path.
3. Repeat the process for all vertices as the intermediate vertex.

The time complexity of the Floyd-Warshall algorithm is O(V^3)
### dfs
Depth-First Search (DFS) is an algorithm used to search through graphs or trees. It starts at a given node and explores as far as possible along each branch before backtracking.
DFS works as follows:

1. Start at the root node
2. Visit the current node and mark it as visited.
3. Recursively visit each unvisited adjacent node, going as deep as possible along each path.
4. Backtrack when no unvisited adjacent nodes are left, and continue to the next unvisited node.

The time complexity of DFS is 𝑂(𝑉+𝐸),
### bfs
Breadth-First Search (BFS) is an algorithm used to search through graphs or trees. It starts at a given node and explores all of its neighboring nodes at the present depth before moving on to nodes at the next depth level.
BFS works as follows:

1. Start at the root node 
2. Visit the current node and mark it as visited.
3. Add all unvisited adjacent nodes to a queue.
4. Dequeue a node from the front of the queue, visit it, and mark it as visited.
5. Repeat steps 3 and 4 until the queue is empty.

BFS uses a queue to keep track of nodes to be explored, ensuring that nodes are explored in order of their depth from the starting node. The time complexity of BFS is 𝑂(𝑉+𝐸)
### 堆
A heap is a special tree-based data structure that satisfies the heap property. There are two types of heaps: min-heaps and max-heaps. In a min-heap, the value of each node is greater than or equal to the value of its parent, making the smallest value at the root. In a max-heap, the value of each node is less than or equal to the value of its parent, making the largest value at the root.
The primary operations on a heap include:

1. **Insertion**: Add a new element to the heap and maintain the heap property by "bubbling up" the element to its correct position.
2. **Deletion**: Remove the root element  and maintain the heap property by "bubbling down" the last element to its correct position.
3. **Peek**: Access the root element without removing it.

The time complexity for insertion, deletion, and peek operations in a binary heap is O(log n).
### 并查集
Union-Find, is a data structure that keeps track of a partition of a set into subsets. It is used to efficiently manage and merge sets and is commonly used in network connectivity and Kruskal's algorithm for finding the minimum spanning tree.
The main operations of a Disjoint Set are:

1. **Find**: Determine which subset a particular element is in. This can be used to check if two elements are in the same subset.
2. **Union**: Merge two subsets into a single subset.

To improve the efficiency of these operations, two techniques are commonly used:
1. **Path Compression**: During the Find operation, make each node point directly to the root, flattening the structure of the tree and speeding up future operations.
2. **Union by Rank**: Always attach the smaller tree to the root of the larger tree to keep the tree as flat as possible.

With these optimizations, both Find and Union operations can be performed in nearly constant time, specifically O(α(n)), where α is the inverse Ackermann function, which grows very slowly.
### 动态规划
Dynamic Programming (DP) is a method for solving complex problems by breaking them down into simpler subproblems. It is used when the problem can be divided into overlapping（重叠） subproblems that can be solved independently.

Dynamic Programming works as follows:
1. Identify the subproblems and solve each one only once.
2. Store the results of subproblems in a table to avoid redundant calculations.
3. Use these stored results to build up solutions to larger problems.

- **Top-Down (Memoization)**: Solve the problem recursively and store the results of subproblems.
- **Bottom-Up (Tabulation)**: Solve the smallest subproblems first and use their results to iteratively solve larger subproblems.

Dynamic Programming is efficient for problems with overlapping subproblems and optimal substructure, like the Fibonacci sequence, shortest path problems, and knapsack problem.
### 贪心
A greedy algorithm is a problem-solving method that makes a series of choices, each of which looks the best at the moment. The goal is to find the overall optimal solution by making a sequence of locally optimal choices.
Greedy algorithms work as follows:

1. Start with an empty solution.
2. At each step, add the best current choice to the solution.
3. Repeat until the solution is complete or all choices have been considered.

Greedy algorithms are used when a problem has the "greedy-choice property," meaning a locally optimal choice will lead to a globally optimal solution. They are often simpler and faster than other algorithms but don't always guarantee an optimal solution for every problem. Common examples include: