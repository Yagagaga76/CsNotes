{"path":"pdf/ÁÆóÊ≥ïËÆæËÆ°‰∏éÂàÜÊûê/L19 - NPC2.pdf","text":"Introduction to Algorithm Design and Analysis [19] NP Complete Problems 2 Jingwei Xu https://ics.nju.edu.cn/~xjw Institute of Computer Software Nanjing University In the Last Class‚Ä¶ ‚Ä¢ Decision Problem ‚Ä¢ The Class P ‚Ä¢ The Class NP In This Class ‚Ä¢ Reduction between problems ‚Ä¢ NP-Complete Problems ‚Ä¢ No known polynomial time algorithm ‚Ä¢ Computationally related by reduction ‚Ä¢ Other advanced topics ‚Ä¢ Advanced algorithms ‚Ä¢ Advanced computation models ReductionNP-complete Problems ‚Ä¢ A problem Q is NP-hard if every problem P in NP is reducible to Q, that is P‚â§ P Q. ‚Ä¢ (which means that Q is at least as hard as any problem in NP ) ‚Ä¢ A problem Q is NP-complete if it is in NP and is NP- hard. ‚Ä¢ (which means that Q is at most as hard as to be solved by a polynomially bounded nondeterministic algorithm) Example of an NP-hard problem ‚Ä¢ Halt problem: Given an arbitrary deterministic algorithm A and an input I, does A with input I ever terminate? ‚Ä¢ A well‚Äêknown undecidable problem, of course not in NP . ‚Ä¢ SatisÔ¨Åability problem is reducible to it. ‚Ä¢ Construct an algorithm A whose input is a propositional formula X. If X has n variables then A tries out all 2 n possible truth assignments and veriÔ¨Åes if X is satisÔ¨Åable. If it is satisÔ¨Åable then A stops. Otherwise, A enters an inÔ¨Ånite loop. ‚Ä¢ So, A halts on X iÔ¨Ä. X is satisÔ¨Åable. More Undecidable Problems ‚Ä¢ Arithmetical SAT ‚Ä¢ The tiling problem P and NP - Revisited ‚Ä¢ Intuition implies that NP is a much larger set than P. ‚Ä¢ No one problem in NP has been proved not in P. ‚Ä¢ If any NP ‚Äêcompleted problem is in P, then NP=P. ‚Ä¢ Which means that every problems in NP can be reducible to a problem in P! ‚Ä¢ Much more questionable P and NP - Revisited Procedure for NP-Completeness ‚Ä¢ Knowledge: P is NPC ‚Ä¢ Task: to prove that Q is NPC ‚Ä¢ Approach: to reduce P to Q ‚Ä¢ For any R‚ààNP , R ‚â§ P P ‚Ä¢ Show P ‚â§ P Q ‚Ä¢ Then R ‚â§ P Q, by transitivity of reductions ‚Ä¢ Done. Q is NP‚Äêcomplete (given that Q has been proven in NP) First Known NPC Problem ‚Ä¢ Cook‚Äôs theorem: ‚Ä¢ The SAT problem is NP‚Äêcomplete. ‚Ä¢ Reduction as tool for proving NP- completeness ‚Ä¢ Since CNF‚ÄêSAT is known to be NP‚Äêhard, then all the problems, to which CNF‚ÄêSAT is reducible, are also NP‚Äêhard. So, the formidable task of proving NP‚Äê complete is transformed into relatively easy task of proving of being in NP. Proof of Cook‚Äôs Theorem SatisÔ¨Åability Problem ‚Ä¢ CNF ‚Ä¢ A literal is a Boolean variable or a negated Boolean variable, as x or ùë•ÃÖ ‚Ä¢ A clause is several literals connected with ‚à® s, as ùë• \u0000 ‚à® ùë• \u0000 ‚Ä¢ A CNF formula is several clause connected with ‚àß s ‚Ä¢ CNF‚ÄêSAT problem ‚Ä¢ Is a given CNF formula satisÔ¨Åable, i.e. taking the value TRUE on some assignments for all x i . ‚Ä¢ A special case: 3‚ÄêSAT ‚Ä¢ 3‚ÄêSAT: each clause can contain at most 3 literals Proving NPC by Reduction ‚Ä¢ The CNF-SAT problem is NP -complete. ‚Ä¢ Prove problem Q is NP-complete, given a problem P known to be NP -complete ‚Ä¢ For all R‚ààNP, R‚â§ P P; ‚Ä¢ Show P‚â§ P Q; ‚Ä¢ By transitivity of reduction, for all R‚ààNP, R‚â§ P Q; ‚Ä¢ So, Q is NP‚Äêhard; ‚Ä¢ If Q is in NP as well, then Q is NP‚Äêcomplete. Max Clique Problem is NP CNF-SAT to Clique ‚Ä¢ LetœÜ=C 1 ‚ãÄC 2 ‚ãÄ‚Ä¶‚ãÄC k be a formula in CNF-3with k clauses. For r =1,2,...,k, each clause C r =(l 1r ‚ãÅl 2 r ‚ãÅl 3r ), l i r is x i or ¬¨x i , any of the variables in the formula. ‚Ä¢ A graph can be constructed as follows. For each C r , create a triple of vertices v 1 r , v 2 r and v 3 r , and create edges between v ir and v j s if and only if: ‚Ä¢ they are in diÔ¨Äerent triples, i.e. r‚â†s, and ‚Ä¢ they do not correspond to the literals negating each other (Note: there is no edges within one triple) 3-CNF Graph Clique Problem is NP-Complete ‚Ä¢ œÜ, with k clauses, is satisÔ¨Åable iff. The graph G has a clique of size k. ‚Ä¢ Proof: ‚Ä¢ Suppose that œÜ has a satisfying assignment. ‚Ä¢ Then there is at least one ‚Äútrue‚Äù literal in each clause. Picking such a literal from each clause, their corresponding vertices in G can be proved to be a clique, since any two of them are in diÔ¨Äerent triples and cannot be complements to each other (they are both true). ‚Ä¢ Known NP-Complete Problems ‚Ä¢ Garey & Johnson: Computer and Intractability: A Guide to the Theory of NP- Completeness, Freeman, 1979 ‚Ä¢ About 300 problems, grouped in 12 categories: 1. Graph Theory 2. Network Design 3. Set and Partition 4. Storing and Retrieving 5. Sorting and Scheduling 6. Mathematical Planning 7. Algebra and Number Theory 8. Games and Puzzles 9. Logic 10. Automata and Theory of Languages 11. Optimization of Programs 12. Miscellaneous Advanced Topics ‚Ä¢ Solving hard problems ‚Ä¢ Approximation algorithms ‚Ä¢ Randomized algorithms ‚Ä¢ Solving more complex problems ‚Ä¢ Online algorithms ‚Ä¢ External memory models ‚Ä¢ Distributed computation models Approximation ‚Ä¢ Make modiÔ¨Åcations on the problem ‚Ä¢ Restrictions on the input ‚Ä¢ Change the criteria for the output ‚Ä¢ Find new abstractions for a practical situation ‚Ä¢ Find approximate solution ‚Ä¢ Algorithm ‚Ä¢ Bound of the errors Bin Packing Problem ‚Ä¢ Suppose we have ‚Ä¢ An unlimited number of bins each of capacity one, and n objects with sizes s 1 , s 2 , ..., s n where 0<s i ‚â§1 (s i are rational numbers) ‚Ä¢ Optimization problem ‚Ä¢ Determine the smallest number of bins into which the objects can be packets (and Ô¨Ånd an optimal packing) . ‚Ä¢ Bin packing is a NPC problem Feasible Solution ‚Ä¢ Set of feasible solutions ‚Ä¢ For any given input I={s 1 ,s 2 ,...,s n }, the feasible solution set, FS(I) is the set of all valid packing using any number of bins. ‚Ä¢ In other words, that is the set of all partitions of I into disjoint subsets T 1 ,T 2 ,...,T p , for some p, such that the total of the s i in any subset is at most 1. Optimal Solution ‚Ä¢ In the bin packing problem, the optimization parameter is the number of bins used. ‚Ä¢ For any given input I and a feasible solution x, val(I,x) is the value of the optimization parameter. ‚Ä¢ For a given input I, the optimum value, opt(I)=min{val(I,x) | x‚ààFS(I)} ‚Ä¢ An optimal solution for I is a feasible solution which achieves the optimum value. Approximate Algorithm ‚Ä¢ An approximation algorithm A for a problem ‚Ä¢ Polynomial‚Äêtime algorithm that, when given input I, output an element of FS(I). ‚Ä¢ Quality of an approximation algorithm. ‚Ä¢ RA(m) = max {r A (I) | I such that opt(I)=m} ‚Ä¢ Bounded RA(m) ‚Ä¢ For an approximation algorithm, we hope the value of RA(m) is bounded by small constants. r A (I) = val(I, A(I)) opt(I) r A (I) = opt(I) val(I, A(I)) or First Fit Decreasing - FFD ‚Ä¢ The strategy: packing the largest as possible ‚Ä¢ Example: S=(0.8, 0.5, 0.4, 0.4, 0.3, 0.2, 0.2, 0.2) This is NOT an optimal solution! The Procedure Small Objects in Extra Bins ‚Ä¢ Problem formulation ‚Ä¢ Let S={s1, s2, ..., sn} be an input, in nonincreasing order ‚Ä¢ Let opt(S) be the minimum number of bins for S. ‚Ä¢ All of the objects placed by FFD in the extra bins have size at most 1/3. ‚Ä¢ Let i be the index of the Ô¨Årst object placed by FFD in bin opt(S)+1. ‚Ä¢ What we have to do for the proof is: s i ‚â§1/3. What about a s i Larger than 1/3? ‚Ä¢ [S is sorted] The s 1 ,s 2 ,...,s i-1 are all larger than 1/3. ‚Ä¢ So, bin B j for j=1,...,opt(S) contain at most 2 objects ‚Ä¢ Then, for some k‚â•0, the Ô¨Årst k bins contain one object each and the remaining opt(S)-k bins contain two each. ‚Ä¢ Proof: no situation (that is, some bin containing 2 objects has a smaller index than some bin containing only one object) as the following is possible B p B q p<q Then, we must have: t>v, u>s i , so v+s i <1, no extra bin is needed! Considering S i Contradiction at Last! ‚Ä¢ Any optimal solution use only opt(S) bins. ‚Ä¢ However, there are k bins that do not contain any of the objects k+1, ..., i-1, i. k+1,..., i-1 must occupy opt(S)-k bins, with each bin containing 2. ‚Ä¢ Since all objects down through to s i are larger than 1/3, s i can not Ô¨Åt in any of the opt(S)-k bins. ‚Ä¢ So, extra bin needed, and contradiction. Objected in Extra Bins Bounded ‚Ä¢ For any input S={s 1 , s 2 ,...,s n }, the number of objects placed by FFD in extra bins is at most opt(S)-1. A Good Approximation ‚Ä¢ Using FFD, the number of bins used is at most about 1/3 more than optimal value. FFD puts at most m‚Äê1 objects in extra bins, and the size of the m‚Äê1 object are at most 1/3 each, so, FFD uses at most ‚åà(m‚Äê1)/3‚åâ extra bins. R FFD (m) ‚â§ 4 3 + 1 3m r FFD (S) ‚â§ m + ‚åà m ‚àí 1 3 ‚åâ m ‚â§ 1 + m + 1 3m ‚â§ 4 3 + 1 3m Average Performance is Much Better ‚Ä¢ Empirical Studies on large inputs. ‚Ä¢ The number of extra bins are estimated by the amount of empty space in the packings produced by the algorithm. ‚Ä¢ It has been shown that for n objects with sizes uniformly distributed between zero and one, the expected amount of empty space in packings by FFD is approximately 0.3‚àön. Randomized Algorithm ‚Ä¢ Mote Carlo ‚Ä¢ Always Ô¨Ånish in time ‚Ä¢ The answer may be incorrect ‚Ä¢ Las Vegas ‚Ä¢ Always return the correct answer ‚Ä¢ The running time varies a lot Online Algorithm ‚Ä¢ The main difference ‚Ä¢ OÔ¨Ñine algorithm: you can obtain all your input in advance ‚Ä¢ Online algorithm: you must cope with unpredictable inputs ‚Ä¢ How to analyze an online algorithm ‚Ä¢ Competitive analysis: the performance of an online algorithm is compared to that of an optimal oÔ¨Ñine algorithm Distributed Data ‚Ä¢ External memory model Distributed Computation ‚Ä¢ Model of distributed computation Thank you! Q & A","libVersion":"0.2.4","langs":""}